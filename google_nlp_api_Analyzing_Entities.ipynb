{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS']='/home/neophilex/.ssh/sa-neophilex-alpha-owner.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_analyze_entities(text_content= 'California is a state.'):\n",
    "    from google.cloud import language\n",
    "    from google.cloud.language import enums\n",
    "    \"\"\"\n",
    "    Analyzing Entities in a String\n",
    "\n",
    "    Args:\n",
    "      text_content The text content to analyze\n",
    "    \"\"\"\n",
    "\n",
    "    client = language.LanguageServiceClient()\n",
    "\n",
    "    # text_content = 'California is a state.'\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"en\"\n",
    "    document = {\"content\": text_content, \"type\": type_, \"language\": language}\n",
    "\n",
    "    # Available values: NONE, UTF8, UTF16, UTF32\n",
    "    encoding_type = enums.EncodingType.UTF8\n",
    "\n",
    "    response = client.analyze_entities(document, encoding_type=encoding_type)\n",
    "\n",
    "    # Loop through entitites returned from the API\n",
    "    for entity in response.entities:\n",
    "        print(u\"Representative name for the entity: {}\".format(entity.name))\n",
    "\n",
    "        # Get entity type, e.g. PERSON, LOCATION, ADDRESS, NUMBER, et al\n",
    "        print(u\"Entity type: {}\".format(enums.Entity.Type(entity.type).name))\n",
    "\n",
    "        # Get the salience score associated with the entity in the [0, 1.0] range\n",
    "        print(u\"Salience score: {}\".format(entity.salience))\n",
    "\n",
    "        # Loop over the metadata associated with entity. For many known entities,\n",
    "        # the metadata is a Wikipedia URL (wikipedia_url) and Knowledge Graph MID (mid).\n",
    "        # Some entity types may have additional metadata, e.g. ADDRESS entities\n",
    "        # may have metadata for the address street_name, postal_code, et al.\n",
    "        for metadata_name, metadata_value in entity.metadata.items():\n",
    "            print(u\"{}: {}\".format(metadata_name, metadata_value))\n",
    "\n",
    "        # Loop over the mentions of this entity in the input document.\n",
    "        # The API currently supports proper noun mentions.\n",
    "        for mention in entity.mentions:\n",
    "            print(u\"Mention text: {}\".format(mention.text.content))\n",
    "\n",
    "            # Get the mention type, e.g. PROPER for proper noun\n",
    "            print(\n",
    "                u\"Mention type: {}\".format(enums.EntityMention.Type(mention.type).name)\n",
    "            )\n",
    "\n",
    "    # Get the language of the text, which will be the same as\n",
    "    # the language specified in the request or, if not specified,\n",
    "    # the automatically-detected language.\n",
    "    print(u\"Language of the text: {}\".format(response.language))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representative name for the entity: California\n",
      "Entity type: LOCATION\n",
      "Salience score: 1.0\n",
      "wikipedia_url: https://en.wikipedia.org/wiki/California\n",
      "mid: /m/01n7q\n",
      "Mention text: California\n",
      "Mention type: PROPER\n",
      "Mention text: state\n",
      "Mention type: COMMON\n",
      "Language of the text: en\n"
     ]
    }
   ],
   "source": [
    "sample_analyze_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_analyze_entities_uri(gcs_content_uri = 'gs://cloud-samples-data/language/entity.txt'):\n",
    "    from google.cloud import language\n",
    "    from google.cloud.language import enums\n",
    "    \"\"\"\n",
    "    Analyzing Entities in text file stored in Cloud Storage\n",
    "\n",
    "    Args:\n",
    "      gcs_content_uri Google Cloud Storage URI where the file content is located.\n",
    "      e.g. gs://[Your Bucket]/[Path to File]\n",
    "    \"\"\"\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # gcs_content_uri = 'gs://cloud-samples-data/language/entity.txt'\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"en\"\n",
    "    document = {\"gcs_content_uri\": gcs_content_uri, \"type\": type_, \"language\": language}\n",
    "\n",
    "    # Available values: NONE, UTF8, UTF16, UTF32\n",
    "    encoding_type = enums.EncodingType.UTF8\n",
    "\n",
    "    response = client.analyze_entities(document, encoding_type=encoding_type)\n",
    "    # Loop through entitites returned from the API\n",
    "    for entity in response.entities:\n",
    "        print(u\"Representative name for the entity: {}\".format(entity.name))\n",
    "        # Get entity type, e.g. PERSON, LOCATION, ADDRESS, NUMBER, et al\n",
    "        print(u\"Entity type: {}\".format(enums.Entity.Type(entity.type).name))\n",
    "        # Get the salience score associated with the entity in the [0, 1.0] range\n",
    "        print(u\"Salience score: {}\".format(entity.salience))\n",
    "        # Loop over the metadata associated with entity. For many known entities,\n",
    "        # the metadata is a Wikipedia URL (wikipedia_url) and Knowledge Graph MID (mid).\n",
    "        # Some entity types may have additional metadata, e.g. ADDRESS entities\n",
    "        # may have metadata for the address street_name, postal_code, et al.\n",
    "        for metadata_name, metadata_value in entity.metadata.items():\n",
    "            print(u\"{}: {}\".format(metadata_name, metadata_value))\n",
    "\n",
    "        # Loop over the mentions of this entity in the input document.\n",
    "        # The API currently supports proper noun mentions.\n",
    "        for mention in entity.mentions:\n",
    "            print(u\"Mention text: {}\".format(mention.text.content))\n",
    "            # Get the mention type, e.g. PROPER for proper noun\n",
    "            print(\n",
    "                u\"Mention type: {}\".format(enums.EntityMention.Type(mention.type).name)\n",
    "            )\n",
    "\n",
    "    # Get the language of the text, which will be the same as\n",
    "    # the language specified in the request or, if not specified,\n",
    "    # the automatically-detected language.\n",
    "    print(u\"Language of the text: {}\".format(response.language))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representative name for the entity: California\n",
      "Entity type: LOCATION\n",
      "Salience score: 1.0\n",
      "wikipedia_url: https://en.wikipedia.org/wiki/California\n",
      "mid: /m/01n7q\n",
      "Mention text: California\n",
      "Mention type: PROPER\n",
      "Mention text: state\n",
      "Mention type: COMMON\n",
      "Language of the text: en\n"
     ]
    }
   ],
   "source": [
    "sample_analyze_entities_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
