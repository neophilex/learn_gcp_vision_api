{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cloud.google.com/natural-language/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language_v1\n",
    "from google.cloud.language_v1 import enums\n",
    "\n",
    "\n",
    "def sample_analyze_entity_sentiment(text_content = 'Grapes are good. Bananas are bad.'):\n",
    "    \"\"\"\n",
    "    Analyzing Entity Sentiment in a String\n",
    "\n",
    "    Args:\n",
    "      text_content The text content to analyze\n",
    "    \"\"\"\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # text_content = 'Grapes are good. Bananas are bad.'\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"en\"\n",
    "    document = {\"content\": text_content, \"type\": type_, \"language\": language}\n",
    "\n",
    "    # Available values: NONE, UTF8, UTF16, UTF32\n",
    "    encoding_type = enums.EncodingType.UTF8\n",
    "\n",
    "    response = client.analyze_entity_sentiment(document, encoding_type=encoding_type)\n",
    "    # Loop through entitites returned from the API\n",
    "    for entity in response.entities:\n",
    "        print(u\"Representative name for the entity: {}\".format(entity.name))\n",
    "        # Get entity type, e.g. PERSON, LOCATION, ADDRESS, NUMBER, et al\n",
    "        print(u\"Entity type: {}\".format(enums.Entity.Type(entity.type).name))\n",
    "        # Get the salience score associated with the entity in the [0, 1.0] range\n",
    "        print(u\"Salience score: {}\".format(entity.salience))\n",
    "        # Get the aggregate sentiment expressed for this entity in the provided document.\n",
    "        sentiment = entity.sentiment\n",
    "        print(u\"Entity sentiment score: {}\".format(sentiment.score))\n",
    "        print(u\"Entity sentiment magnitude: {}\".format(sentiment.magnitude))\n",
    "        # Loop over the metadata associated with entity. For many known entities,\n",
    "        # the metadata is a Wikipedia URL (wikipedia_url) and Knowledge Graph MID (mid).\n",
    "        # Some entity types may have additional metadata, e.g. ADDRESS entities\n",
    "        # may have metadata for the address street_name, postal_code, et al.\n",
    "        for metadata_name, metadata_value in entity.metadata.items():\n",
    "            print(u\"{} = {}\".format(metadata_name, metadata_value))\n",
    "\n",
    "        # Loop over the mentions of this entity in the input document.\n",
    "        # The API currently supports proper noun mentions.\n",
    "        for mention in entity.mentions:\n",
    "            print(u\"Mention text: {}\".format(mention.text.content))\n",
    "            # Get the mention type, e.g. PROPER for proper noun\n",
    "            print(\n",
    "                u\"Mention type: {}\".format(enums.EntityMention.Type(mention.type).name)\n",
    "            )\n",
    "\n",
    "    # Get the language of the text, which will be the same as\n",
    "    # the language specified in the request or, if not specified,\n",
    "    # the automatically-detected language.\n",
    "    print(u\"Language of the text: {}\".format(response.language))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_analyze_entity_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language_v1\n",
    "from google.cloud.language_v1 import enums\n",
    "\n",
    "\n",
    "def sample_analyze_entity_sentiment_uri(gcs_content_uri = 'gs://cloud-samples-data/language/entity-sentiment.txt'):\n",
    "    \"\"\"\n",
    "    Analyzing Entity Sentiment in text file stored in Cloud Storage\n",
    "\n",
    "    Args:\n",
    "      gcs_content_uri Google Cloud Storage URI where the file content is located.\n",
    "      e.g. gs://[Your Bucket]/[Path to File]\n",
    "    \"\"\"\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # gcs_content_uri = 'gs://cloud-samples-data/language/entity-sentiment.txt'\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"en\"\n",
    "    document = {\"gcs_content_uri\": gcs_content_uri, \"type\": type_, \"language\": language}\n",
    "\n",
    "    # Available values: NONE, UTF8, UTF16, UTF32\n",
    "    encoding_type = enums.EncodingType.UTF8\n",
    "\n",
    "    response = client.analyze_entity_sentiment(document, encoding_type=encoding_type)\n",
    "    # Loop through entitites returned from the API\n",
    "    for entity in response.entities:\n",
    "        print(u\"Representative name for the entity: {}\".format(entity.name))\n",
    "        # Get entity type, e.g. PERSON, LOCATION, ADDRESS, NUMBER, et al\n",
    "        print(u\"Entity type: {}\".format(enums.Entity.Type(entity.type).name))\n",
    "        # Get the salience score associated with the entity in the [0, 1.0] range\n",
    "        print(u\"Salience score: {}\".format(entity.salience))\n",
    "        # Get the aggregate sentiment expressed for this entity in the provided document.\n",
    "        sentiment = entity.sentiment\n",
    "        print(u\"Entity sentiment score: {}\".format(sentiment.score))\n",
    "        print(u\"Entity sentiment magnitude: {}\".format(sentiment.magnitude))\n",
    "        # Loop over the metadata associated with entity. For many known entities,\n",
    "        # the metadata is a Wikipedia URL (wikipedia_url) and Knowledge Graph MID (mid).\n",
    "        # Some entity types may have additional metadata, e.g. ADDRESS entities\n",
    "        # may have metadata for the address street_name, postal_code, et al.\n",
    "        for metadata_name, metadata_value in entity.metadata.items():\n",
    "            print(u\"{} = {}\".format(metadata_name, metadata_value))\n",
    "\n",
    "        # Loop over the mentions of this entity in the input document.\n",
    "        # The API currently supports proper noun mentions.\n",
    "        for mention in entity.mentions:\n",
    "            print(u\"Mention text: {}\".format(mention.text.content))\n",
    "            # Get the mention type, e.g. PROPER for proper noun\n",
    "            print(\n",
    "                u\"Mention type: {}\".format(enums.EntityMention.Type(mention.type).name)\n",
    "            )\n",
    "\n",
    "    # Get the language of the text, which will be the same as\n",
    "    # the language specified in the request or, if not specified,\n",
    "    # the automatically-detected language.\n",
    "    print(u\"Language of the text: {}\".format(response.language))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_analyze_entity_sentiment_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
