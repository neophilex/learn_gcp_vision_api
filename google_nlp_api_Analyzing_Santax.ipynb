{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language_v1\n",
    "from google.cloud.language_v1 import enums\n",
    "\n",
    "\n",
    "def sample_analyze_syntax(text_content):\n",
    "    \"\"\"\n",
    "    Analyzing Syntax in a String\n",
    "\n",
    "    Args:\n",
    "      text_content The text content to analyze\n",
    "    \"\"\"\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # text_content = 'This is a short sentence.'\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"en\"\n",
    "    document = {\"content\": text_content, \"type\": type_, \"language\": language}\n",
    "\n",
    "    # Available values: NONE, UTF8, UTF16, UTF32\n",
    "    encoding_type = enums.EncodingType.UTF8\n",
    "\n",
    "    response = client.analyze_syntax(document, encoding_type=encoding_type)\n",
    "    # Loop through tokens returned from the API\n",
    "    for token in response.tokens:\n",
    "        # Get the text content of this token. Usually a word or punctuation.\n",
    "        text = token.text\n",
    "        print(u\"Token text: {}\".format(text.content))\n",
    "        print(\n",
    "            u\"Location of this token in overall document: {}\".format(text.begin_offset)\n",
    "        )\n",
    "        # Get the part of speech information for this token.\n",
    "        # Parts of spech are as defined in:\n",
    "        # http://www.lrec-conf.org/proceedings/lrec2012/pdf/274_Paper.pdf\n",
    "        part_of_speech = token.part_of_speech\n",
    "        # Get the tag, e.g. NOUN, ADJ for Adjective, et al.\n",
    "        print(\n",
    "            u\"Part of Speech tag: {}\".format(\n",
    "                enums.PartOfSpeech.Tag(part_of_speech.tag).name\n",
    "            )\n",
    "        )\n",
    "        # Get the voice, e.g. ACTIVE or PASSIVE\n",
    "        print(u\"Voice: {}\".format(enums.PartOfSpeech.Voice(part_of_speech.voice).name))\n",
    "        # Get the tense, e.g. PAST, FUTURE, PRESENT, et al.\n",
    "        print(u\"Tense: {}\".format(enums.PartOfSpeech.Tense(part_of_speech.tense).name))\n",
    "        # See API reference for additional Part of Speech information available\n",
    "        # Get the lemma of the token. Wikipedia lemma description\n",
    "        # https://en.wikipedia.org/wiki/Lemma_(morphology)\n",
    "        print(u\"Lemma: {}\".format(token.lemma))\n",
    "        # Get the dependency tree parse information for this token.\n",
    "        # For more information on dependency labels:\n",
    "        # http://www.aclweb.org/anthology/P13-2017\n",
    "        dependency_edge = token.dependency_edge\n",
    "        print(u\"Head token index: {}\".format(dependency_edge.head_token_index))\n",
    "        print(\n",
    "            u\"Label: {}\".format(enums.DependencyEdge.Label(dependency_edge.label).name)\n",
    "        )\n",
    "\n",
    "    # Get the language of the text, which will be the same as\n",
    "    # the language specified in the request or, if not specified,\n",
    "    # the automatically-detected language.\n",
    "    print(u\"Language of the text: {}\".format(response.language))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language_v1\n",
    "from google.cloud.language_v1 import enums\n",
    "\n",
    "\n",
    "def sample_analyze_syntax_uri(gcs_content_uri = 'gs://cloud-samples-data/language/syntax-sentence.txt'):\n",
    "    \"\"\"\n",
    "    Analyzing Syntax in text file stored in Cloud Storage\n",
    "\n",
    "    Args:\n",
    "      gcs_content_uri Google Cloud Storage URI where the file content is located.\n",
    "      e.g. gs://[Your Bucket]/[Path to File]\n",
    "    \"\"\"\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # gcs_content_uri = 'gs://cloud-samples-data/language/syntax-sentence.txt'\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"en\"\n",
    "    document = {\"gcs_content_uri\": gcs_content_uri, \"type\": type_, \"language\": language}\n",
    "\n",
    "    # Available values: NONE, UTF8, UTF16, UTF32\n",
    "    encoding_type = enums.EncodingType.UTF8\n",
    "\n",
    "    response = client.analyze_syntax(document, encoding_type=encoding_type)\n",
    "    # Loop through tokens returned from the API\n",
    "    for token in response.tokens:\n",
    "        # Get the text content of this token. Usually a word or punctuation.\n",
    "        text = token.text\n",
    "        print(u\"Token text: {}\".format(text.content))\n",
    "        print(\n",
    "            u\"Location of this token in overall document: {}\".format(text.begin_offset)\n",
    "        )\n",
    "        # Get the part of speech information for this token.\n",
    "        # Parts of spech are as defined in:\n",
    "        # http://www.lrec-conf.org/proceedings/lrec2012/pdf/274_Paper.pdf\n",
    "        part_of_speech = token.part_of_speech\n",
    "        # Get the tag, e.g. NOUN, ADJ for Adjective, et al.\n",
    "        print(\n",
    "            u\"Part of Speech tag: {}\".format(\n",
    "                enums.PartOfSpeech.Tag(part_of_speech.tag).name\n",
    "            )\n",
    "        )\n",
    "        # Get the voice, e.g. ACTIVE or PASSIVE\n",
    "        print(u\"Voice: {}\".format(enums.PartOfSpeech.Voice(part_of_speech.voice).name))\n",
    "        # Get the tense, e.g. PAST, FUTURE, PRESENT, et al.\n",
    "        print(u\"Tense: {}\".format(enums.PartOfSpeech.Tense(part_of_speech.tense).name))\n",
    "        # See API reference for additional Part of Speech information available\n",
    "        # Get the lemma of the token. Wikipedia lemma description\n",
    "        # https://en.wikipedia.org/wiki/Lemma_(morphology)\n",
    "        print(u\"Lemma: {}\".format(token.lemma))\n",
    "        # Get the dependency tree parse information for this token.\n",
    "        # For more information on dependency labels:\n",
    "        # http://www.aclweb.org/anthology/P13-2017\n",
    "        dependency_edge = token.dependency_edge\n",
    "        print(u\"Head token index: {}\".format(dependency_edge.head_token_index))\n",
    "        print(\n",
    "            u\"Label: {}\".format(enums.DependencyEdge.Label(dependency_edge.label).name)\n",
    "        )\n",
    "\n",
    "    # Get the language of the text, which will be the same as\n",
    "    # the language specified in the request or, if not specified,\n",
    "    # the automatically-detected language.\n",
    "    print(u\"Language of the text: {}\".format(response.language))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_analyze_syntax_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
